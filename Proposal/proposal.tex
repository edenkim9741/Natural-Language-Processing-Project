\documentclass[11pt]{article}

\usepackage{../mystyle}

\doublespacing
% \setlength{\parindent}{0pt}


\title{발음 기반 한국어 단어 Retrieval}
\author{pronouncy}
\date{}

\begin{document}
\maketitle
\tableofcontents

\section{Motivation}
번역기를 포함한 많은 검색 시스템은 주로 형태소를 분석하여 입력쿼리와 문서 간의 철자적 유사성 혹은 의미적 유사성을 기반으로 검색을 수행한다.
이러한 시스템은 사용자가 정확한 철자, 표준어를 사용하지 않거나 모르는 경우에는 정확한 검색 결과를 제공하지 못한다는 문제가 있다.

이중 언어 학습자의 한국어 작문에 나타난 오류 특성 분석에 관한 연구 \cite{__2012}에 따르면, 한국어를 배우는 외국인 학습자들의 전체 어휘 오류 중 약 84\%가 맞춤법 오류로 나타났다. 외국인 학습자들에게 있어 한국어의 맞춤법은 한국어를 학습하는 데 있어 가장 큰 장벽 중 하나로 작용하고 있다는 것을 알 수 있다.

% 이와는 대조적으로 실제 사용자는 단어의 철자를 정확하게 알고 있지 않거나, 비표준어 혹은 외래어를 입력하는 상황이 많다.
% 예를 들어, 한국어를 공부하는 외국인 사용자가 `호닌신고'라는 단어를 입력한 경우에는
% `혼인신고'라는 단어를 입력하고자 했을 가능성이 높다.
% 하지만 
외국인뿐만 아니라 현재 흔히 사용되는 Google 번역기나 Deep Learning 기반의 DeepL 번역기는 `호닌신고'라는 단어를 입력했을 때 honin report라는 영어 단어를 제시한다.
번역기에서 단어를 번역함에 있어 발음의 유사성은 고려하지 않기 때문에 올바른 번역을 제공하지 못하는 현상으로 볼 수 있다.

이러한 문제를 해결하기 위해서는 사용자가 입력한 단어의 발음을 기반으로 검색을 수행하는 시스템이 필요하다고 판단하였다.

\section{Task Definition}
입력으로 소리나는대로 적힌 한국어 단어가 주어졌을 때, 해당 단어의 발음을 기반으로 올바른 한국어 단어를 검색하는 시스템을 구축하고자 한다.
소리나는대로 작성한 단어를 올바른 단어로 변환하는 방법을 제안함으로써 한국어 학습에 도움이 될 수 있을 것으로 기대한다.

\section{Dataset}
\subsection{g2p}
잘못된 발음의 단어를 입력으로 받아서 올바른 단어를 출력하는 시스템은 많지 않지만 올바른 단어를 입력으로 받아서 소리나는대로 단어를 재구성하여 출력하는 시스템은 쉽게 찾을 수 있다.
해당 task는 g2p(Grammer to Phoneme) task라고 불리고, 한국어의 경우에는 `g2pk' \cite{park2019g2pk} 라는 라이브러리로 구현되어 있다.

\subsection{Dataset Generation}
g2p 시스템을 사용하여 올바른 한국어 단어를 입력으로 받아서 소리나는대로 재구성 된 단어를 출력하는 시스템을 구축할 수 있다.
이 때 사용할 입력으로는 AI HUB의 `문서요약 텍스트'와 `대규모 웹데이터 기반 한국어 말뭉치 데이터'를 선택하였다.

AI HUB의 `문서요약 텍스트'는 뉴스 기사를 요약한 데이터로, 법률, 사설, 신문기사의 텍스트를 포함하고 있다.
용량은 약 401.21MB이며, table \ref{tab:aihub1}에서 세부적인 정보를 확인할 수 있다.

\begin{table}[h]
    \centering
    \begin{tabular}{lll}
        \multicolumn{1}{c}{\textbf{데이터 종류}} & \multicolumn{1}{c}{\textbf{데이터 형태}} & \multicolumn{1}{c}{\textbf{목표 수량}} \\ \hline
        신문기사                                & 뉴스 텍스트                              & 원문데이터 30만 건 / 요약문 60만 건            \\
        기고문                                 & 오피니언 텍스트                            & 원문데이터 6만건 / 요약문 12만 건              \\
        잡지                                  & 웹진 기사 텍스트                           & 원문데이터 1만 건 / 요약문 2만 건              \\
        법률                                  & 법원 판결문 뉴스 텍스트 및 법원 주요 판결문 텍스트       & 원문데이터 3만 건 / 요약문 6만 건              \\
        \multicolumn{2}{l}{총계}              & 원문데이터 40만 건 / 요약문 80만 건
    \end{tabular}
    \caption{AI HUB의 문서요약 텍스트 데이터}
    \label{tab:aihub1}
\end{table}

AI HUB의 `대규모 웹데이터 기반 한국어 말뭉치 데이터'는 웹사이트 기반 (메가 뉴스) 대용량의 텍스트 데이터를 수집 후 전사 도구를 활용하여 타이틀, 단락 제목, 본문 텍스트로 구조화한 약 10억 어절의 데이터로 구성되어 있다. 용량은 약 9GB이며, table \ref{tab:aihub2}에서 세부적인 정보를 확인할 수 있다.

\begin{table}[h]
    \centering
    \begin{tabular}{cccccc}
        \textbf{No.}                    & \textbf{분류코드}   & \textbf{분류명}           & \textbf{파일수}     & \textbf{어절 수} & \textbf{비율} \\ \hline
        1                               & SC              & IT/과학                  & 1,535            & 41,970,255    & 3.6\%       \\
        2                               & CU              & 문화/패션/뷰티               & 2,280            & 44,853,911    & 3.8\%       \\
        3                               & IN              & 국제                     & 2,752            & 49,390,134    & 4.2\%       \\
        4                               & WO              & 여성복지                   & 3,420            & 49,970,850    & 4.3\%       \\
        5                               & ED              & 교육                     & 3,371            & 57,060,422    & 4.9\%       \\
        6                               & LC              & 지역                     & 3,962            & 57,954,012    & 4.9\%       \\
        7                               & LI              & 라이프스타일                 & 3,732            & 62,600,032    & 5.3\%       \\
        8                               & SP              & 스포츠                    & 3,178            & 62,942,643    & 5.4\%       \\
        9                               & AC              & 사건사고                   & 3,562            & 65,350,073    & 5.6\%       \\
        10                              & HE              & 건강                     & 4,403            & 68,648,804    & 5.8\%       \\
        11                              & HB              & 취미                     & 3,672            & 70,524,485    & 6.0\%       \\
        12                              & SG              & 사회일반                   & 4,501            & 74,946,093    & 6.4\%       \\
        13                              & TL              & 여행레저                   & 4,063            & 79,220,922    & 6.7\%       \\
        14                              & PO              & 정치                     & 4,153            & 93,955,104    & 8.0\%       \\
        15                              & EC              & 경제                     & 6,140            & 97,426,330    & 8.3\%       \\
        16                              & EN              & 연예                     & 5,996            & 98,190,180    & 8.4\%       \\
        17                              & ID              & 산업                     & 5,031            & 100,459,770   & 8.5\%       \\
        \multicolumn{3}{c}{\textbf{합계}} & \textbf{65,751} & \textbf{1,175,464,020} & \textbf{100.0\%}
    \end{tabular}
    \caption{AI HUB의 대규모 웹데이터 기반 한국어 말뭉치 데이터}
    \label{tab:aihub2}
\end{table}

위 두 데이터셋을 입력으로 활용하여 g2p 시스템을 통해 소리나는대로 재구성 된 단어를 생성할 수 있다.
하지만 g2p는 한국어의 음운법칙을 기반으로하여 단어를 재구성하기 때문에, 한국어의 음운법칙을 따르지 않는 단어는 같은 소리를 내더라도 생성되지 않는다.
그렇기 때문에 우리는 음절의 끝소리 규칙, 모음 조화 규칙, 자음군 단순화 규칙 등을 조금씩 변형하여 같은 소리를 내는 문자열을 여러 개 생성할 수 있도록 할 계획이다.

\section{Method}
\subsection{Phonetic Embedding}
phonetic embedding은 발음 정보를 기반으로 단어를 벡터로 변환하는 방법이다. 발음 정보를 추출하기 위해서 우리는 TTS(Text To Speech)를 사용하여 각 단어를 음성으로 변환하고, 이를 음성 인식 모델을 통해 음성에서 텍스트로 변환하여 발음 정보를 추출하기로 하였다.

사용할 TTS 모델로는 `Naver Clova TTS', `OnAir Studio Voice', `Typecast TTS' 등 여러 모델을 테스트할 예정이다.
\subsection{Semantic Embedding}
입력으로 주어진 단어가 소리나는대로 재구성 된 단어임에도 불구하고, BERT 모델과 같은 LLM 모델을 사용하면 의미적인 정보도 함께 추출할 수 있다.

BERT 모델을 fine tuning 하면서 소리나는대로 재구성 된 단어와 올바른 단어를 pair로 학습하여 의미적인 정보를 유사하게 만들 수 있다고 생각하였고, 자주 오용되는 단어들은 Pretraining 과정에서도 어느 정도 학습이 되었을 것이라고 생각하였다.

\subsection{Retrieval}
Phonetic Embedding과 Semantic Embedding을 결합하여 얻은 벡터를 사용하여 단어를 유사도 기반으로 정렬하거나 Decoder를 학습하여 가장 유사한 단어를 생성할 수 있도록 할 예정이다.

\section{Experiments}
\subsection{Translation Performance Measurement}
소리나는대로 입력한 문장을 번역하는 Task에서 발음 정보를 포함하여 Embedding한 Vector 더 좋은 성능을 가질 것으로 예상하였기 때문에, 기존의 모델로 Embedding한 Vector와 발음 정보를 포함하여 Embedding한 Vector를 활용하여 각각 Translation을 수행한 후 성능을 비교하기로 하였다. Translation task를 위해서 Pretraining된 Decoder를 활용할 예정이다.

\subsection{Evaluation Metric}
정확도를 평가하기 위해서 Precision@k, Recall@k, F1@k를 사용하기로 하였다.
Precision@k는 상위 k개의 예측 중에서 정답인 예측의 비율을 의미하고, Recall@k는 정답 중에서 상위 k개의 예측에 포함된 정답의 비율을 의미한다.
\begin{equation*}
    Precision@k = \frac{TP}{TP + FP}
\end{equation*}
\begin{equation*}
    Recall@k = \frac{TP}{TP + FN}
\end{equation*}

F1@k는 Precision@k와 Recall@k의 조화 평균함으로써 얻을 수 있다.
\begin{equation*}
    F1@k = \frac{2 \cdot Precision@k \cdot Recall@k}{Precision@k + Recall@k}
\end{equation*}
\subsection{Ablation Study}
우리는 발음 정보가 올바른 단어를 찾는 데에 도움이 될 것이라고 생각하였고, 이를 검증하기 위해서 Ablation Study를 진행할 예정이다.

발음 벡터를 추출하지 않고 semantic embedding만을 사용하여 단어를 유사도 기반으로 정렬한 경우와, 발음 벡터를 추출하지 않고 phonetic embedding만을 사용하여 단어를 유사도 기반으로 정렬한 경우와 비교하여 성능을 평가하기로 하였다.

또한 추출된 벡터를 통해 Decoder를 학습하여 가장 유사한 단어를 생성하는 경우와, 추출된 벡터를 사용하여 단어를 유사도 기반으로 정렬한 경우와 비교하여 성능을 평가하기로 하였다.

\section{Schedule}
진행할 프로젝트의 일정은 table \ref{tab:schedule}과 같다.
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{주차} & \textbf{일정}                  & \textbf{내용}     \\ \hline
        1주차       & $\sim$ 2025.4.30             & 데이터셋 수집 및 전처리   \\ \hline
        2,3주차       & 2025.05.01 $\sim$ 2025.05.14 & 모델 설계 및 구현      \\ \hline
        4,5주차       & 2025.05.15 $\sim$ 2025.05.28 & 모델 학습 및 평가      \\ \hline
        6주차         & 2025.05.29 $\sim$ 2025.06.04 & 결과 분석           \\ \hline
        7주차         & 2025.06.05 $\sim$ 2025.06.11 & 보고서 작성, 발표자료 제작 \\ \hline
    \end{tabular}
    \caption{일정}
    \label{tab:schedule}
\end{table}

\section{Team Members \& Roles}
팀원 구성 및 역할은 table \ref{tab:team}과 같다.
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{이름} & \textbf{Role} & \textbf{Jobs}                       \\ \hline
        김건형         & 팀장            & 보고서 작성, 발표자료 제작, 모델 구현              \\ \hline
        구동한         & 팀원            & 데이터셋 구축 및 전처리, Background 조사, 실험 설계 \\ \hline
        이준연         & 팀원            & 모델 구현, 결과 분석                        \\ \hline
    \end{tabular}
    \caption{팀원 구성}
    \label{tab:team}
\end{table}


\bibliographystyle{unsrt}
\bibliography{ref}

\end{document}