%File: anonymous-submission-latex-2025.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[]{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
\usepackage[outputdir=./temps]{minted}
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{subcaption}
%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{kotex}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2025.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
\nocopyright
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai25.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{발음 정보를 이용한 한국어 Text-Phonetic Encoder \\
        \normalsize Final Report}
\author{
    % %Authors
    % % All authors must be in the same font size and format.
    % Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
    % AAAI Style Contributions by Pater Patel Schneider,
    % Sunil Issar,\\
    % J. Scott Penberthy,
    % George Ferguson,
    % Hans Guesgen,
    % Francisco Cruz\equalcontrib,
    % Marc Pujol-Gonzalez\equalcontrib
    pronouncy
}
\affiliations{
    %Afiliations
    % \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
    % If you have multiple authors and multiple affiliations
    % use superscripts in text and roman font to identify them.
    % For example,

    % Sunil Issar\textsuperscript{\rm 2},
    % J. Scott Penberthy\textsuperscript{\rm 3},
    % George Ferguson\textsuperscript{\rm 4},
    % Hans Guesgen\textsuperscript{\rm 5}
    % Note that the comma should be placed after the superscript

    % 1101 Pennsylvania Ave, NW Suite 300\\
    % Washington, DC 20004 USA\\
    % % email address must be in roman text type, not monospace or sans serif
    % proceedings-questions@aaai.org
    김건형, 이준연, 구동한
%
% See more examples next
}

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name\textsuperscript{\rm 1},
    Second Author Name\textsuperscript{\rm 2},
    Third Author Name\textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1}Affiliation 1\\
    \textsuperscript{\rm 2}Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
    한국어 학습자에게 있어 한글 발음과 실제 표기 간의 차이는 큰 장벽이 될 수 있다.
    특히 음운 변화가 복잡하고 발음과 표기가 일치하지 않는 단어가 많은 한국어의 특성은 학습 난이도를 증가시킨다. 이러한 문제를 해결하기 위해, 본 프로젝트에서는 기존의 Text Embedding Vector와 Phonetic Embedding Vector를 결합한 Text-Phonetic Encoder를 설계하고, 이를 통해 발음 정보를 인식하는 한국어 자연어 처리를 가능하게 하는 시스템을 개발하고자 한다.
    또한 발음대로 잘못 표기된 단어 데이터셋 구축을 위해 G2PK\cite{park2019g2pk}를 변형하여 올바르게 표기된 문장에 대해 발음 기반으로 잘못 표기된 단어를 생성하는 시스템을 개발하였다.
    코드는 \url{https://github.com/edenkim9741/Natural-Language-Processing-Project.git}에서 확인할 수 있다.
\end{abstract}

% Uncomment the following to link to your code, datasets, an extended version or similar.
%
% \begin{links}
%     \link{Code}{https://aaai.org/example/code}
%     \link{Datasets}{https://aaai.org/example/datasets}
%     \link{Extended version}{https://aaai.org/example/extended-version}
% \end{links}

\section{1. Introduction}
한국어는 발음과 표기가 일치하지 않는 경우가 많기 때문에 한국어 학습자에게 있어 읽기, 쓰기 및 말하기에 있어 큰 장벽이 될 수 있다.
특히 한국어는 음운 변화가 복잡하여 발음과 표기가 그 주변 단어나 어미, 문맥에 따라 달라지는 경우가 많다. 예를 들어, `밟다'라는 단어는 `밥다'로 발음하지만, `밟은'이라는 단어는 `발븐'으로 발음한다.
기존의 Transformer 기반의 Text Encoder는 입력된 문장을 정확하게 표기하는 것을 전제로 하기 때문에, 발음대로 잘못 표기된 단어를 처리하는 데 한계가 있고, 발음대로 잘못 표기된 단어는 Tokenizer에서 정확한 Token으로 분리되지 않아 의미를 파악하기 어렵다.
이러한 문제를 해결하기 위해, 본 프로젝트에서는 TTS(Text-to-Speech)를 활용하여 발음 정보를 벡터화하고, 이를 통해 발음 정보를 인식하는 한국어 자연어 처리를 가능하게 하는 시스템을 개발하고자 한다.
본 프로젝트의 기여는 다음과 같다.
\begin{itemize}
    \item 한국어에서 발음 기반의 모델의 필요성을 제기하고, 이를 해결하기 위한 Text-Phonetic Encoder 설계
    \item 발음대로 잘못 표기된 단어 데이터셋 구축을 위한 G2PK 변형
    \item Text-Phonetic Encoder를 활용한 Downstream Task 실험 설계 및 검증
\end{itemize}
\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/text_dataset_example.png}
    \caption{Text Dataset Example}
    \label{fig:text_dataset_example}
\end{figure*}
\section{2. Related Works}
\subsection{2.1. G2PK}
G2PK(graphemes to phonemes for korean)에서는 한국어 문장을 입력받아 해당 문장의 발음을 추출하는 패키지이다.
Appendix의 G2PK Rule\ref{sec:g2pk_rule}에서 G2PK의 변형 규칙을 확인할 수 있다.
하지만 기존의 G2PK는 국립국어원에서 정해진 음운 규칙에 따라 문장을 변형하기 때문에 한국어 학습자가 발음대로 잘못 표기한 단어를 생성하기에는 한계가 있다.
예를 들어, `있습니다'라는 단어는 G2PK에 의해 `읻씀니다'로 변형되지만, 한국어 학습자가 발음대로 잘못 표기할 수 있는 단어는 `잇습니다', `잇씁니다', `잇슴니다' 등 다양한 형태가 존재한다.

\subsection{2.2. Text Encoder}
Text Encoder는 텍스트 데이터를 고차원 임베딩 공간으로 매핑하는 역할을 수행하며, 자연어 처리(NLP) 및 멀티모달 학습에서 핵심적인 구성 요소로 작용한다. 전통적으로는 Word2Vec, GloVe, ELMo 등의 단어 수준 임베딩이 널리 사용되었으나, 최근에는 Transformer 기반의 문맥 기반 인코더(예: BERT, RoBERTa, DeBERTa 등)가 주류로 자리잡았다. 이들 모델은 대규모 비지도 사전학습(pretraining)을 통해 문장 및 단어 간의 정교한 의미 관계를 포착할 수 있으며, 다양한 downstream task에 전이 학습이 가능하다.

특히 BERT(Bidirectional Encoder Representations from Transformers)는 양방향 self-attention 구조를 통해 문맥의 양방향 정보를 효과적으로 활용할 수 있으며, 이후 등장한 RoBERTa, ALBERT, ELECTRA 등은 학습 효율성 및 성능 향상을 위한 다양한 변형을 포함하고 있다. 이러한 인코더들은 문장 분류, 질의 응답, 텍스트 요약 등에서 뛰어난 성능을 보이며, 음성 인식이나 TTS와 결합된 멀티모달 모델에서도 중요한 역할을 수행한다.


\subsection{2.3. Text-to-Speech (TTS)}
Text-to-Speech(TTS)는 텍스트 형태의 입력을 자연스러운 음성으로 변환하는 기술로, 인간과의 상호작용이 필요한 다양한 애플리케이션(예: 음성 비서, 내비게이션, 접근성 기술 등)에 필수적으로 활용된다. 초기의 TTS 시스템은 규칙 기반(rule-based) 또는 통계적 파라미터 방식(statistical parametric speech synthesis; SPSS)에 기반했으나, 이는 제한된 표현력과 부자연스러운 발음으로 인해 한계를 보였다.

최근에는 딥러닝 기반의 TTS 모델들이 등장하면서 음질과 자연스러움이 크게 향상되었다. 대표적인 end-to-end TTS 모델로는 Tacotron, FastSpeech, Glow-TTS, VITS 등이 있으며, 이들은 음성의 스펙트로그램을 직접 예측하고 이를 보코더(vocoder; 예: WaveNet, HiFi-GAN)를 통해 파형으로 복원하는 방식을 따른다. 특히, FastSpeech 계열 모델은 병렬화(parallelization)가 가능하여 실시간 응답이 중요한 응용에 적합하며, VITS는 Variational Autoencoder와 Normalizing Flow를 통합하여 더 다양한 발화 표현과 고음질을 동시에 달성하였다.

본 프로젝트에서는 텍스트로부터 Phonetic Embedding Vector를 추출하기 위해 mms-tts-kor\cite{pratap2023mms}를 사용하였다. mms-tts-kor는 다국어 TTS 모델로 학습된 mms-tts을 한국어에 pre-training된 모델이다. 한국어의 다양한 발음과 억양을 지원하여 한국어 발음 정보를 효과적으로 추출할 수 있다.

\subsection{2.4. Wav2Vec2}
Wav2Vec 2.0은 Facebook AI에서 제안한 음성 기반 self-supervised learning 모델로, 대규모 비정제 음성 데이터(raw audio)를 활용하여 강력한 음성 표현(audio representation)을 학습할 수 있게 한다. 기존의 Wav2Vec은 CNN 기반 encoder를 통해 음성의 잠재 표현(latent representation)을 추출하고, 이를 학습된 quantizer를 통해 음소 수준의 분류를 가능하게 했으나, Wav2Vec 2.0에서는 Transformer 기반 contextual encoder를 도입하고, contrastive learning을 활용하여 더욱 정교한 음성 특성 표현을 가능하게 한다.

Wav2Vec 2.0은 음성 인식 뿐 아니라, 발화 화자 특성 보존, 감정 인식, 음성 합성 등 다양한 음성 응용 분야에서 pre-trained encoder로 활용되며, 최근에는 multilingual pretraining, speaker adaptation, phonetic decoding 등의 연구로 확장되고 있다. 본 연구는 이러한 Wav2Vec 2.0의 강력한 음성 표현 학습 능력을 기반으로, 발음 정보를 효과적으로 벡터화하고, 이를 통해 한국어 자연어 처리에서의 발음 인식 문제를 해결하고자 한다.

\section{3. Dataset}

\subsection{3.1. Text Dataset}
Text Dataset은 한국어-영어 번역 데이터셋\cite{aihub_korean_english_parallel}을 통해 만들어졌다. Dataset은 json 파일 형식으로 문장의 번호와 올바른 한국어 문장 1개, 번역된 영어 문장 1개, 발음대로 잘못 표기된 한국어 문장 최대 5개로 이루어져있다. 해당 오류들은 Modifed G2PK를 통해 생성되었으며, 각 오류들은 G2PK의 문장 변형 과정에서 랜덤하게 선택된다. Figure \ref{fig:text_dataset_example}은 Text Dataset의 예시를 보여준다.


\subsection{3.2. Phonetic Dataset}
학습 과정에 Text-To-Speech(TTS) 과정을 포함하기에는 시간과 비용이 많이 소모되기 때문에 Text Dataset의 발음대로 잘못 표기된 문장을 TTS(Text-to-Speech)를 통해 음성으로 변환한 wav 파일과 해당 wav 파일을 Wav2Vec2를 통해 벡터화한 결과로 구성된 Phonetic Dataset을 별도로 구축하였다. 추론 과정에서는 TTS로 변환하는 과정이 포함되어 있음에 유의해야 한다.

\section{4. Methods}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/model_architecture.pdf}
    \caption{Text-Phonetic Encoder Architecture}
    \label{fig:phonetic_encoder}
\end{figure*}

\subsection{4.1. Modified G2PK}
기존 G2PK는 음운 규칙에 따라 문장을 변형하는 방식으로, 한국어 학습자가 발음대로 잘못 표기한 단어를 생성하기에는 한계가 있다.
따라서 본 프로젝트에서는 아래와 같은 규칙을 추가하여 한국어 학습자가 발음대로 잘못 표기할 수 있는 단어들을 생성하는 시스템을 개발하였다.
\begin{itemize}
    \item 한국어 학습자가 제대로 표기하는 방법을 알고 있는 경우를 고려하여 제대로 표기하는 경우도 모든 규칙에 대해 추가한다.
          \begin{itemize}
              \item 있습니다[있습니다, 읻씀니다, 잇슴니다, ...]
          \end{itemize}
    \item 한국어 학습자가 받침을 표기할 때 'ㅅ, ㅆ, ㅈ, ㅊ, ㅌ'을 [ㅅ, ㅆ]으로 표기하는 경우가 있다.
          \begin{itemize}
              \item 썼다[썻따]
              \item 쫓다[쫏따]
              \item 쫓기다[쫏끼다]
          \end{itemize}
    \item 용언의 어간 말음 `ㄺ'은 `ㄱ' 앞에서 [ㄹ]로 발음하지만, 한국어 학습자는 `ㄱ'으로 발음하는 경우가 있다.
          \begin{itemize}
              \item 맑게[말께, 막께]
              \item 묽고[물꼬, 묵꼬]
              \item 읽거나[일꺼나, 익꺼나]
          \end{itemize}
    \item ㅎ+ㄱ 거센소리화, ㅎ 보존
          \begin{itemize}
            \item 놓고[놓코]
          \end{itemize}
    \item ㅎ(ㄶ)+ㄱ 거센소리화, ㅎ 보존
            \begin{itemize}
                \item 잃고[읽코]
            \end{itemize}
    \item $\dots$
\end{itemize}

더 자세한 규칙은 Appendix의 Modified G2PK Rule\ref{sec:modified_g2pk_rule}에서 확인할 수 있다.


\subsection{4.2. Text-Phonetic Encoder}
Text-Phonetic Encoder는 기존 Text Encoder와 Phonetic Feature를 결합하여 발음 정보를 인식하는 Encoder이다.
Text-Phonetic Encoder는 크게 Text Encoder와 Phonetic Encoder, Fusion Layer로 구성되어 있다. Text Encoder는 입력된 문장을 Tokenize하고, 이를 기존에 학습된 Encoder에 입력하여 문장의 Text Embedding Vector를 생성한다.
Fusion Layer는 Text Embedding Vector와 Phonetic Embedding Vector를 Projection하여 최종 임베딩 벡터를 생성한다.

\subsubsection{Text Encoder}
Text Encoder는 입력된 문장을 Tokenizer를 통해 Tokenize하고 학습하면서 각 Token에 대한 Text Embedding Vector를 생성한다.
발음과 표기가 거의 유사한 문장의 경우, 발음대로 표기된 단어일지라도 기존 단어와 유사한 Token들과 Text Embeddng Vector를 가질 수 있다.
예를 들어, `사과'라는 단어는 발음대로 표기하더라도 `사과'이므로 동일한 Token과 Embedding Vector를 가진다.

본 프로젝트에서는 koBert Encoder를 사용하였고, HuggingFace에서 제공하는 pre-trained 모델을 사용했다.
Text Encoder에서 생성된 Text Embedding Vector $\mathbf{v}_t$는 [T, 768]의 크기를 가지고, 문장의 의미적 정보를 포함하고 있다.


\subsubsection{Phonetic Encoder}
Phonetic Encoder는 Text Dataset의 발음대로 잘못 표기된 문장을 TTS(Text-to-Speech)를 통해 음성 오디오 데이터로 변환하고, 오디오 데이터를 Wav2Vec2를 통해 벡터화한 결과로 구성된다.
최종적으로 변환된 Phonetic Embedding Vector $\mathbf{v}_p$는 [768]의 크기를 가지며, 발음 정보를 포함하고 있다.


\subsubsection{Fusion Layer}
Fusion Layer는 Text Encoder와 Phonetic Encoder의 출력 벡터를 결합하여 최종 임베딩 벡터를 생성하는 모듈이다.
이를 위해 Text Encoder와 Phonetic Encoder의 출력 벡터를 결합한 후 pytorch에서 제공하는 간단한 FC(Fully Connected) Layer를 사용하여 projection하였다. 이렇게 최종적으로 추출된 Embedding Vector $\mathbf{v}_f$는 발음과 문맥 정보를 모두 포함한 벡터로, 발음 기반의 유사도 비교를 가능하게 한다.

이는 다음과 같은 수식으로 표현할 수 있다.
\begin{equation}
    \mathbf{v}_f = FC (\mathbf{v}_t \oplus \mathbf{v}_p)
\end{equation}

\subsection{4.5. Decoder}
Encoder에서의 Feature가 얼마나 효과적으로 추출되었는지를 평가하기 위해, Text Encoder와 짝을 이루는 koBert의 Decoder를 사용하였다.
Decoder는 Text-Phonetic Encoder의 출력 벡터 $\mathbf{v}_f$를 입력으로 받아, Task에 따라 올바른 문장을 재구성하거나 번역하는 역할을 한다.
본 프로젝트에서 진행한 Downstream Task는 총 2가지로, Reconstruction인지 Translation인지에 따라 데이터셋에서 original\_text와 translate\_text를 이용하여 Cross Entropy Loss를 계산, 학습한다.

\section{5. Experiments}
\subsection{5.1. Text Encoder와 Phonetic Encoder의 유사도 비교}
실제로 Phonetic Feature를 도입하는 것이 효과가 있는지에 대해 확인하기 위해 정답 문장에서 각각 Text Encoder, Phonetic Encoder로 추출한 벡터 $\mathbf{v}_{t,T}, \mathbf{v}_{p,T}$에 대해서 $i$번째 오류 문장을 각각의 Encoder로 추출한 벡터 $\mathbf{v}_{t,i}, \mathbf{v}_{p,i}$의 유사도의 평균을 비교하였다.
\begin{equation}
    avg\_similarity_{t} = \frac{1}{N} \sum_{i=1}^{N} \frac{\mathbf{v}_{t,T} \cdot \mathbf{v}_{t,i}}{||\mathbf{v}_{t,T}|| \cdot ||\mathbf{v}_{t,i}||}
\end{equation}
\begin{equation}
    avg\_similarity_{p} = \frac{1}{N} \sum_{i=1}^{N} \frac{\mathbf{v}_{p,T} \cdot \mathbf{v}_{p,i}}{||\mathbf{v}_{p,T}|| \cdot ||\mathbf{v}_{p,i}||}
\end{equation}
\begin{table}[ht]
    \centering
    \begin{tabular}{lcc}
        Pooling & \multicolumn{1}{l}{Text Encoder} & \multicolumn{1}{l}{Phonetic Encoder} \\ \hline
        CLS     & 0.9597                           &                                      \\
        Mean    & 0.9069                           & 0.9934                               \\
        Max     & 0.9621                           &
    \end{tabular}
    \caption{Text Encoder와 Phonetic Encoder의 유사도 비교 결과}
    \label{tab:encoder_comparison}
\end{table}

비교 결과 Table \ref{tab:encoder_comparison}과 같이 Phonetic Encoder의 Feature Vector가 Text Encoder의 Feature Vector보다 평균 유사도가 높게 나타났다. 이 결과는 Phonetic Encoder가 Modified G2PK로 생성된 발음대로 잘못 표기된 단어들에 대해서 더 강건함을 보여준다.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/tsne_text_embeddings.pdf}
    \caption{Text Encoder의 Embedding Space}
    \label{fig:tsne_text_encoder}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/tsne_phonetic_embeddings.pdf}
    \caption{Phonetic Encoder의 Embedding Space}
    \label{fig:tsne_phonetic_encoder}
\end{figure}

\subsection{5.2. Text Encoder와 Phonetic Encoder의 Embedding Space 비교}
단순 유사도를 비교하는 것은 negetive pair에 대한 유사도를 반영하고 있지 않기 때문에 t-SNE를 활용하여 서로 다른 문장 간의 거리를 유지하면서 Embedding Space를 효과적으로 생성하고 있는지 확인하였다.
Figure \ref{fig:tsne_text_encoder}와 Figure \ref{fig:tsne_phonetic_encoder}는 각각 20개의 문장에 대해 Text Encoder와 Phonetic Encoder로 추출한 Embedding Space를 시각화한 결과이다.

결과를 살펴보면 Text Encoder의 경우 다른 문장과 더 가까운 거리를 가지는 sample이 존재하는 반면, Phonetic Encoder의 경우 발음이 유사한 문장들이 더 가까운 거리를 가지는 것을 확인할 수 있다.

\subsection{5.3. Ablation Study}
Phonetic Feature가 Downstream Task에 미치는 영향을 확인하기 위해, Fusion Layer를 사용하지 않고 Text Encoder와 Decoder만을 사용한 모델, 즉 기존과 동일한 모델과 Text-Phonetic Encoder로부터 추출한 Embedding Vector를 Fusion Layer를 통해 결합한 모델을 비교하였다.
비교를 진행한 Downstream Task는 Reconstruction과 Translation Task이다.
정확히 입력과 동일한 문장을 출력하는 것이 중요하기 때문에 Exact Match와 cer를 사용했고, 틀린 문장에 대해서도 의미를 보존해야하기 때문에  average bleu와 average bert f1을 사용하였다.
또한 좀 더 정확한 검증을 위해 5 fold cross validation을 통해 평균 성능을 비교했다.

\subsubsection{Reconstruction}
\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/recon_exact_match.png}
        \caption{Reconstruction Exact Match}
        \label{fig:recon_exact_match}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/recon_cer.png}
        \caption{Reconstruction cer}
        \label{fig:recon_cer}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/recon_bleu.png}
        \caption{Reconstruction bleu}
        \label{fig:recon_bleu}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/recon_bert_f1.png}
        \caption{Reconstruction bert f1}
        \label{fig:recon_bert_f1}
    \end{subfigure}
    \caption{Reconstruction Ablation Study Results}
    \label{fig:recon_results}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/trans_exact_match.png}
        \caption{Translation Exact Match}
        \label{fig:trans_exact_match}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/trans_cer.png}
        \caption{Translation cer}
        \label{fig:trans_cer}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/trans_bleu.png}
        \caption{Translation bleu}
        \label{fig:trans_bleu}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/trans_bert_f1.png}
        \caption{Translation bert f1}
        \label{fig:trans_bert_f1}
    \end{subfigure}
    \caption{Translation Ablation Study Results}
    \label{fig:trans_results}
\end{figure}


\begin{table}[t]
    \begin{tabular}{cll}
        \textbf{metrics}         & \textbf{Baseline} & \textbf{Text-Phonetic Encoder} \\ \hline
        exact\_match $\uparrow$  & 0.99517           & \textbf{0.99993}         \\
        cer $\downarrow$         & 0.0001441         & \textbf{0.0000025177}    \\
        avg\_bleu $\uparrow$     & 0.99975           & \textbf{0.99999}         \\
        avg\_bert\_f1 $\uparrow$ & 0.9995            & \textbf{0.99999}
    \end{tabular}
    \caption{Reconstruction Ablation Study Results at epoch 5}
    \label{tab:recon_results}
\end{table}

\begin{table}[t]
    \begin{tabular}{cll}
        \textbf{metrics}         & \multicolumn{1}{c}{\textbf{Baseline}} & \multicolumn{1}{c}{\textbf{Text-Phonetic Encoder}} \\ \hline
        exact\_match $\uparrow$  & 0.99611                               & \textbf{0.99703}                             \\
        cer $\downarrow$         & 0.000050744                           & \textbf{0.000040341}                         \\
        avg\_bleu $\uparrow$     & 0.99994                               & \textbf{0.99995}                             \\
        avg\_bert\_f1 $\uparrow$ & 0.99998                               & 0.99998
    \end{tabular}
    \caption{Translation Ablation Study Results at epoch 5}
    \label{tab:trans_results}
\end{table}


Reconstruction Task에서는 Figure \ref{fig:recon_results}와 같이 phonetic feature와 함께 학습한 경우 모든 지표에서 성능이 향상되었음을 확인할 수 있다. epoch 5에서의 최종 성능만을 표로 나타내면 Table \ref{tab:recon_results}와 같다.

Reconstruction Task에서 잘못 Reconstruction된 문장에 대해서도 살펴보았다. Table \ref{tab:wrong_cases}을 보면 특정한 단어에 대해서 반복적으로 틀리는 모습을 볼 수 있었다. `훌륭한'을 자꾸 `훌륭'이라고 예측하는데, 이는 `훌륭'이라는 단어를 TTS가 정확하게 발음하지 못했기 때문으로 볼 수 있다.

\begin{table*}[h]
    \centering
    \begin{tabular}{|p{7cm}|p{7cm}|}
        \hline
        \textbf{모델 예측 (오답)}                       & \textbf{정답 문장}                             \\
        \hline
        훌륭 한미관계를 이어주는 역할을 하게 해주신 오바마 대통령과 \dots   & 훌륭한 한미관계를 이어주는 역할을 하게 해주신 오바마 대통령과 \dots   \\
        \hline
        훌륭 세일즈맨은 본인이 판단하는 것이 아니고, 고객이 인정해 줘야 합니다. & 훌륭한 세일즈맨은 본인이 판단하는 것이 아니고, 고객이 인정해 줘야 합니다. \\
        \hline
        훌륭 분들의 삶이 살아 숨쉬는 도시야말로 진정한 명품도시고, \dots   & 훌륭한 분들의 삶이 살아 숨쉬는 도시야말로 진정한 명품도시고, \dots   \\
        \hline
    \end{tabular}
    \caption{모델 오답 사례 정리}
    \label{tab:wrong_cases}
\end{table*}




\subsubsection{Translation}

Translation Task에서는 Figure \ref{fig:trans_results}와 같이 ablation study와 성능적 차이가 거의 없었음을 볼 수 있었다. epoch 5에서의 최종 성능만을 표로 나타내면 Table \ref{tab:trans_results}와 같다. Reconstruction Task와 비교했을 때 성능 차이가 거의 없음을 확인할 수 있다.

이유를 분석해보았을 때에는 Translation Task에서는 Phoentic 정보가 큰 역할을 하지 못하는 것으로 볼 수 있다.
영어와 같이 한국어 발음과 연관이 없는 경우, 기존의 Text Encoder와 큰 차이가 없기 때문일 것으로 보인다.



\section{6. Conclusion}
본 프로젝트에서는 한국어 학습자에게 발음과 표기가 일치하지 않는 문제를 해결하기 위해 Text-Phonetic Encoder를 설계하고, 이를 통해 발음 정보를 인식하는 한국어 자연어 처리를 가능하게 하는 시스템을 개발하였다.
Reconstruction과 같은 Task에서는 발음 정보를 추가했을 때 성능이 향상되었고, Translation과 같은 Task에서는 발음 정보가 큰 영향을 미치지 않는 것을 확인하였다.

하지만 본 프로젝트를 진행하며 여러 한계도 발견할 수 있었다. 우선 학습이 끝난 모델로 예측을 했을 때에는 원하는 출력을 볼 수 없었다. 
이는 Encoder Decoder 구조에서 예측을 할 때, 순차적으로 생성된 토큰을 다시 입력으로 넣어주는 방식으로 진행되기 때문에, 정확한 문장을 생성할 수 없는 것으로 보인다.

\section{7. Review and Feedback}
\subsection{7.1 김건형}
최신 LLM 기반의 자연어 처리 모델에 대해서 자세하게 강의해주시는 것이 좋았습니다. 하지만 수업 평가가 프로젝트만으로 이루어지다보니, 저 자신도 수업에 덜 집중하게 되었던 것 같습니다. 물론 배운 내용을 프로젝트에 적용해볼 수 있었으나, 적용에 있어서는 세부적인 내용을 몰라도 어느 정도 진행할 수 있었기 때문에 후반부로 갈수록 수업에 대한 집중도가 떨어졌던 것 같습니다.

또한 팀 프로젝트를 진행하면서 학습 자원이 부족했던 것이 아쉬웠습니다. 진행한 프로젝트 특성상 LLM을 다시 학습시키는 과정이 필요했는데, 모델의 훈련 시간이 굉장이 오래 걸리다보니 초기에 기획했던 여러 모델에 대한 테스트가 이루어지지 않았던 점이 아쉬웠습니다.

이러한 프로젝트의 현실적인 문제와 집중도가 떨어지는 문제를 해결하기 위해서 중간고사나 기말고사 중 하나라도 시행해보는 것이 좋을 것 같다고 생각합니다. 그렇게 된다면 여러 요소로 인해 프로젝트를 잘 진행하지 못했더라도 시험을 통해 어느 정도 만회가 가능할 것이라고 생각합니다.

한 학기동안 열정 넘치는 수업 감사합니다.

\subsection{7.2 이준연}
단순 머신러닝, 딥러닝 이론을 넘어서 비록 학부 수준에선 깊이보단 맛보기 느낌이 강했지만 최신 자연어처리 관련 연구 트렌드를 파악할 수 있었다는 점이 향후 연구를 하는데에 있어 방향 설정에 도움이 되었습니다.

단순 이론보다는 프로젝트성 수업이라 힘든 점은 분명 존재했지만, 직접 데이터셋을 전처리 및 변환하고 모델링에 기여하는 점을 통해서 그 만큼 많이 배우고 성장할 수 있었다. 

프로젝트 단 1회만으로 평가를 받아서인지, 이론 수업에 대해 중요성을 느끼시는 학우분들이 별로 없는 것 같아보여 교수님 혼자 수업하신다는 느낌이 조금 안타까웠다. 그래서 다음 학기부터는 프로젝트에 대한 비중을 조금 줄이고, 이론 수업 기반의 중간 고사 1회나 쪽지지험이나 퀴즈 같은 걸 약 2회정도 추가해보는 것이 어떨까 제안해 봅니다!!

\subsection{7.3 구동한}
자연어 처리 분야에 대해 넓은 범위로 내용을 다루어 전체적인 맥락과 흐름을 공부하고 이해하는 데에 많이 도움이 된 것 같습니다. 또한 후반에 최근 트렌드와 관련된 내용을 통해 자연어 처리에 대한 인사이트도 얻을 수 있어 좋았던 것 같습니다.

프로젝트를 하면서 모델 개발을 위해 데이터를 다루는 것에 그 데이터에 대한 도메인 지식을 제대로 알고 이해하고 있어야 한다는 것을 느낄 수 있는 시간이었습니다. 기존의 데이터에서 변형이나 활용을 통해 새로운 데이터셋을 구축하는 것이 이러한 도메인을 잘 알고 있어야 제대로 된 데이터셋을 구축할 수 있고 프로젝트를 원활히 진행할 수 있다는 것을 깨닫게 되었습니다.

지금의 방식도 크게 문제 없이 괜찮은 것 같습니다.


\section{Appendix}
\subsection{G2PK Rule} \label{sec:g2pk_rule}
G2PK는 다음과 같은 규칙으로 입력 문장을 발음대로 재구성한다.

\begin{minted}[breaklines, fontsize=\scriptsize]{markdown}
5.1
5항. 다만 1. 용언의 활용형에 나타나는 '져, 쪄, 쳐'는 [저, 쩌, 처]로 발음한다.
-> 가져[가저], 쪄[쩌], 다쳐[다처]

5.2
5항. 다만 2. '예, 례' 이외의 'ㅖ'는 [ㅔ]로도 발음한다.
-> 계집[계집/게집], 계시다[계시다/게시다]
-> 시계[시계/시게](時計), 연계[연계/연게](連繫)
-> 몌별[몌별/메별](袂別), 개폐[개폐/개페](開閉)
-> 혜택[혜택/헤택](惠澤), 지혜[지혜/지헤](智慧)
# 실제로 언중은 예, 녜, 셰, 쎼 이외의 'ㅖ'는 [ㅔ]로 발음한다. by kyubyong

5.3
5항. 다만 3. 자음을 첫소리로 가지고 있는 음절의 'ㅢ'는 [ㅣ]로 발음한다.
-> 늴리리[닐리리], 닁큼[닝큼], 무늬[무니], 띄어쓰기[띠어쓰기], 씌어[씨어]
-> 틔어[티어], 희어[히어], 희떱다[히떱따], 희망[히망], 유희[유히]

5.4.1
다만 4. 단어의 첫음절 이외의 '의'는 [ㅣ]로 발음함도 허용한다.
-> 주의[주의/주이], 협의[혀븨/혀비]
# 실제로 언중은 높은 확률로 단어의 첫음절 이외의 '의'는 [ㅣ]로 발음한다.

5.4.2
다만 4. 조사 '의'는 [ㅔ]로 발음함도 허용한다.
-> 우리의[우리의/우리에], 강의의[강의의/강이에]
# 실제로 언중은 높은 확률로 조사 '의'는 [ㅔ]로 발음한다.

9
제9항 받침 'ㄲ, ㅋ', 'ㅅ, ㅆ, ㅈ, ㅊ, ㅌ', 'ㅍ'은 어말 또는 자음 앞에서 각각 대표음 [ㄱ, ㄷ, ㅂ]으로 발음한다.
-> 닦다[닥따], 키읔[키윽], 키읔과[키윽꽈], 옷[옫]
-> 웃다[욷따], 있다[읻따], 젖[젇], 빚다[빋따]
-> 꽃[꼳], 쫓다[쫃따], 솥[솓], 뱉다[밷따]
-> 앞[압], 덮다[덥따]

10
제10항 겹받침 'ㄳ', 'ㄵ', 'ㄼ, ㄽ, ㄾ', 'ㅄ'은 어말 또는 자음 앞에서 각각 [ㄱ, ㄴ, ㄹ, ㅂ]으로 발음한다.
-> 넋[넉], 넋과[넉꽈], 앉다[안따], 여덟[여덜]
-> 넓다[널따], 외곬[외골], 핥다[할따], 값[갑]
-> 없다[업:따]

10.1
다만, '밟-'은 자음 앞에서 [밥]으로 발음하고, '넓-'은 다음과 같은 경우에 [넙]으로 발음한다.
-> 1) 밟다[밥따], 밟소[밥쏘], 밟지[밥찌], 밟는[밤:는], 밟게[밥께], 밟고[밥꼬]
-> 2) 넓죽하다[넙쭈카다], 넓둥글다[넙뚱글다]

11
제11항 겹받침 'ㄺ, ㄻ, ㄿ'은 어말 또는 자음 앞에서 각각 [ㄱ, ㅁ, ㅂ]으로 발음한다.
-> 닭[닥], 흙과[흑꽈], 맑다[막따], 늙지[늑찌]
-> 삶[삼], 젊다[점따], 읊고[읍꼬], 읊다[읍따]

11.1
다만, 용언의 어간 말음 'ㄺ'은 'ㄱ' 앞에서 [ㄹ]로 발음한다.
-> 맑게[말께], 묽고[물꼬], 읽거나[일꺼나]

12
제12항 받침 'ㅎ'의 발음은 다음과 같다.
1. 'ㅎ(ㄶ, ㅀ)' 뒤에 'ㄱ, ㄷ, ㅈ'이 결합되는 경우에는, 뒤 음절 첫소리와 합쳐서 [ㅋ, ㅌ, ㅊ]으로 발음한다.
-> 놓고[노코], 좋던[조턴], 쌓지[싸치], 많고[만코]
-> 않던[안턴], 닳지[달치]
[붙임 1] 받침 'ㄱ(ㄺ), ㄷ, ㅂ(ㄼ), ㅈ(ㄵ)'이 뒤 음절 첫소리 'ㅎ'과 결합되는 경우에도, 역시 두 소리를 합쳐서 [ㅋ, ㅌ, ㅍ, ㅊ]으로 발음한다.
-> 각하[가카], 먹히다[머키다], 밟히다[발피다], 맏형[마텽]
-> 좁히다[조피다], 넓히다[널피다], 꽂히다[꼬치다], 앉히다[안치다]
[붙임 2] 규정에 따라 'ㄷ'으로 발음되는 'ㅅ, ㅈ, ㅊ, ㅌ'의 경우에는 이에 준한다.
-> 옷 한 벌[오 탄 벌], 낮 한때[나 탄때], 꽃 한 송이[꼬 탄 송이]
-> 숱하다[수타다]
2. 'ㅎ(ㄶ, ㅀ)' 뒤에 'ㅅ'이 결합되는 경우에는, 'ㅅ'을 [ㅆ]으로 발음한다.
-> 닿소[다쏘], 많소[만쏘], 싫소[실쏘]
3. 'ㅎ' 뒤에 'ㄴ'이 결합되는 경우에는, [ㄴ]으로 발음한다.
-> 놓는[논는], 쌓네[싼네]
[붙임] 'ㄶ, ㅀ' 뒤에 'ㄴ'이 결합되는 경우에는, 'ㅎ'을 발음하지 않는다.
-> 않네[안네], 않는[안는], 뚫네[뚤레], 뚫는[뚤른]
- '뚫네[뚤네→뚤레], 뚫는[뚤는→뚤른]'에 대해서는 제20항 참조.

12.4
4. 'ㅎ(ㄶ, ㅀ)' 뒤에 모음으로 시작된 어미나 접미사가 결합되는 경우에는, 'ㅎ'을 발음하지 않는다.
-> 낳은[나은], 놓아[노아], 쌓이다[싸이다], 많아[마나]
-> 않은[아는], 닳아[다라], 싫어도[시러도]

13
제13항 홑받침이나 쌍받침이 모음으로 시작된 조사나 어미, 접미사와 결합되는 경우에는, 제 음가대로 뒤 음절 첫소리로 옮겨 발음한다.
-> 깎아[까까], 옷이[오시], 있어[이써], 낮이[나지]
-> 꽂아[꼬자], 꽃을[꼬츨], 쫓아[쪼차], 밭에[바테]
-> 앞으로[아프로], 덮이다[더피다]

14
제14항 겹받침이 모음으로 시작된 조사나 어미, 접미사와 결합되는 경우에는, 뒤엣것만을 뒤 음절 첫소리로 옮겨 발음한다. (이 경우, 'ㅅ'은 된소리로 발음함.)
-> 넋이[넉씨], 앉아[안자], 닭을[달글], 젊어[절머]
-> 곬이[골씨], 핥아[할타], 읊어[을퍼], 값을[갑쓸]
-> 없어[업써]

15
제15항 받침 뒤에 모음 'ㅏ, ㅓ, ㅗ, ㅜ, ㅟ'들로 시작되는 실질 형태소가 연결되는 경우에는, 대표음으로 바꾸어서 뒤 음절 첫소리로 옮겨 발음한다.
-> 밭 아래[바 다래] 		늪 앞[느 밥] 		젖어미[저더미] 		맛없다[마덥다]
-> 겉옷[거돋] 		헛웃음[허두슴] 		꽃 위[꼬 뒤]
다만, '맛있다, 멋있다'는 [마싣따], [머싣따]로도 발음할 수 있다.
[붙임] 겹받침의 경우에는 그 중 하나만을 옮겨 발음한다.
-> 넋 없다[너 겁따] 		닭 앞에[다 가페] 		값어치[가 버치] 		값있는[가빈는]

16
제16항 한글 자모의 이름은 그 받침소리를 연음하되, 'ㄷ, ㅈ, ㅊ, ㅋ, ㅌ, ㅍ, ㅎ'의 경우에는 특별히 다음과 같이 발음한다.
-> 디귿이[디그시], 디귿을[디그슬], 디귿에[디그세]
-> 지읒이[지으시], 지읒을[지으슬], 지읒에[지으세]
-> 치읓이[치으시], 치읓을[치으슬], 치읓에[치으세]
-> 키읔이[키으기], 키읔을[키으글], 키읔에[키으게]
-> 티읕이[티으시], 티읕을[티으슬], 티읕에[티으세]
-> 피읖이[피으비], 피읖을[피으블], 피읖에[피으베]
-> 히읗이[히으시], 히읗을[히으슬], 히읗에[히으세]

17
제17항 받침 'ㄷ, ㅌ(ㄾ)'이 조사나 접미사의 모음 'ㅣ'와 결합되는 경우에는, [ㅈ, ㅊ]으로 바꾸어서 뒤 음절 첫소리로 옮겨 발음한다.
-> 곧이듣다[고지듣따], 굳이[구지], 미닫이[미다지]
-> 땀받이[땀바지], 밭이[바치], 벼훑이[벼훌치]
[붙임] 'ㄷ' 뒤에 접미사 '히'가 결합되어 '티'를 이루는 것은 [치]로 발음한다.
-> 굳히다[구치다], 닫히다[다치다], 묻히다[무치다]

18
제18항 받침 'ㄱ(ㄲ, ㅋ, ㄳ, ㄺ), ㄷ(ㅅ, ㅆ, ㅈ, ㅊ, ㅌ, ㅎ), ㅂ(ㅍ, ㄼ, ㄿ, ㅄ)'은 'ㄴ, ㅁ' 앞에서 [ㅇ, ㄴ, ㅁ]으로 발음한다.
-> 먹는[멍는], 국물[궁물], 깎는[깡는], 키읔만[키응만]
-> 몫몫이[몽목씨], 긁는[긍는], 흙만[흥만], 닫는[단는]
-> 짓는[진:는], 옷맵시[온맵시], 있는[인는], 맞는[만는]
-> 젖멍울[전멍울], 쫓는[쫀는], 꽃망울[꼰망울], 붙는[분는]
-> 놓는[논는], 잡는[잠는], 밥물[밤물], 앞마당[암마당]
-> 밟는[밤:는], 읊는[음는], 없는[엄:는], 값매다[감매다]
[붙임] 두 단어를 이어서 한 마디로 발음하는 경우에도 이와 같다.
-> 책 넣는다[챙 넌는다], 흙 말리다[흥 말리다], 옷 맞추다[온 마추다]
-> 밥 먹는다[밤 멍는다], 값 매기다[감 매기다]

19
제19항 받침 'ㅁ, ㅇ' 뒤에 연결되는 'ㄹ'은 [ㄴ]으로 발음한다.
-> 담력[담:녁], 침략[침냑], 강릉[강능], 항로[항:노], 대통령[대:통녕]
[붙임] 받침 'ㄱ, ㅂ' 뒤에 연결되는 'ㄹ'도 [ㄴ]으로 발음한다.
-> 막론[막논→망논], 백리[백니→뱅니], 협력[협녁→혐녁], 십리[십니→심니]

20
제20항 'ㄴ'은 'ㄹ'의 앞이나 뒤에서 [ㄹ]로 발음한다.
-> 1) 난로[날:로], 신라[실라], 천리[철리], 광한루[광:할루], 대관령[대:괄령]
-> 2) 칼날[칼랄], 물난리[물랄리], 줄넘기[줄럼끼], 할는지[할른지]
[붙임] 첫소리 'ㄴ'이 'ㅀ, ㄾ' 뒤에 연결되는 경우에도 이에 준한다.
-> 닳는[달른], 뚫는[뚤른], 핥네[할레]
다만, 다음과 같은 단어들은 'ㄹ'을 [ㄴ]으로 발음한다.
-> 의견란[의견난], 임진란[임진난], 생산량[생산냥]
-> 결단력[결딴녁], 공권력[공꿘녁], 동원령[동:원녕]
-> 상견례[상견녜], 횡단로[횡단노], 이원론[이원논]
-> 입원료[이붠뇨], 구근류[구근뉴]

21
제21항 위에서 지적한 이외의 자음 동화는 인정하지 않는다.
-> 감기[감기], 옷감[옫깜], 있고[읻꼬]
-> 꽃길[꼳낄],	젖먹이[전머기], 문법[문뻡]
-> 꽃밭[꼳빧]

22
제22항 다음과 같은 용언의 어미는 [어]로 발음함을 원칙으로 하되, [여]로 발음함도 허용한다.
-> 피어[피어/피여] 		되어[되어/되여]
[붙임] '이오, 아니오'도 이에 준하여 [이요, 아니요]로 발음함을 허용한다.

23
제23항 받침 'ㄱ(ㄲ, ㅋ, ㄳ, ㄺ), ㄷ(ㅅ, ㅆ, ㅈ, ㅊ, ㅌ), ㅂ(ㅍ, ㄼ, ㄿ, ㅄ)' 뒤에 연결되는 'ㄱ, ㄷ, ㅂ, ㅅ, ㅈ'은 된소리로 발음한다.
-> 국밥[국빱], 깎다[깍따], 넑받이[넉빠지], 삯돈[삭똔]
-> 닭장[닥짱], 칡범[칙뻠], 뻗대다[뻗때다], 옷고름[옫꼬름]
-> 있던[읻떤], 꽂고[꼳꼬], 꽃다발[꼳따발], 낯설다[낟썰다]
-> 밭갈이[받까리], 솥전[솓쩐], 곱돌[곱똘], 덮개[덥깨]
-> 옆집[엽찝], 넓죽하다[넙쭈카다], 읊조리다[읍쪼리다], 값지다[갑찌다]

24
제24항 어간 받침 'ㄴ(ㄵ), ㅁ(ㄻ)' 뒤에 결합되는 어미의 첫소리 'ㄱ, ㄷ, ㅅ, ㅈ'은 된소리로 발음한다.
-> 신고[신꼬], 껴안다[껴안따], 앉고[안꼬], 얹다[언따]
-> 삼고[삼꼬], 더듬지[더듬찌], 닮고[담꼬], 젊지[점찌]
다만, 피동, 사동의 접미사 '-기-'는 된소리로 발음하지 않는다.
-> 안기다[안기다], 감기다[감기다], 굶기다[굼기다], 옮기다[옴기다]

25
제25항 어간 받침 'ㄼ, ㄾ' 뒤에 결합되는 어미의 첫소리 'ㄱ, ㄷ, ㅅ, ㅈ'은 된소리로 발음한다.
-> 넓게[널께], 핥다[할따], 훑소[훌쏘], 떫지[떨찌]

26
제26항 한자어에서, 'ㄹ' 받침 뒤에 연결되는 'ㄷ, ㅅ, ㅈ'은 된소리로 발음한다.
-> 갈등[갈뜽], 발동[발똥], 절도[절또], 말살[말쌀]
-> 불소[불쏘](弗素), 일시[일씨], 갈증[갈쯩], 물질[물찔]
-> 발전[발쩐], 몰상식[몰쌍식], 불세출[불쎄출]
다만, 같은 한자가 겹쳐진 단어의 경우에는 된소리로 발음하지 않는다.
-> 허허실실[허허실실](虛虛實實), 절절하다[절절하다](切切- )

27
제27항 관형사형 '-[으]ㄹ' 뒤에 연결되는 'ㄱ, ㄷ, ㅂ, ㅅ, ㅈ'은 된소리로 발음한다.
-> 할 것을[할 꺼슬], 갈 데가[갈 떼가], 할 바를[할 빠를]
-> 할 수는[할 쑤는], 할 적에[할 쩌게], 갈 곳[갈 꼳]
-> 할 도리[할 또리], 만날 사람[만날 싸람]
다만, 끊어서 말할 적에는 예사소리로 발음한다.
[붙임] '-(으)ㄹ'로 시작되는 어미의 경우에도 이에 준한다.
-> 할걸[할껄], 할밖에[할빠께], 할세라[할쎄라]
-> 할수록[할쑤록], 할지라도[할찌라도], 할지언정[할찌언정]
-> 할진대[할찐대]

28
제28항 표기상으로는 사이시옷이 없더라도, 관형격 기능을 지니는 사이시옷이 있어야 할(휴지가 성립되는) 합성어의 경우에는, 뒤 단어의 첫소리 'ㄱ, ㄷ, ㅂ, ㅅ, ㅈ'을 된소리로 발음한다.
-> 문고리[문꼬리], 눈동자[눈똥자], 신바람[신빠람], 산새[산쌔]
-> 손재주[손째주], 길가[길까], 물동이[물똥이], 발바닥[발빠닥]
-> 굴속[굴쏙], 술잔[술짠], 바람결[바람껼], 그믐달[그믐딸]
-> 아침밥[아침빱], 잠자리[잠짜리], 강가[강까], 초승달[초승딸]
-> 등불[등뿔], 창살[창쌀], 강줄기[강쭐기]

29
제29항 합성어 및 파생어에서, 앞 단어나 접두사의 끝이 자음이고 뒤 단어나 접미사의 첫 음절이 '이, 야, 여, 요, 유'인 경우에는, 'ㄴ'소리를 첨가하여 [니, 냐, 녀, 뇨, 뉴]로 발음한다.
-> 솜이불[솜니불], 홑이불[혼니불], 막일[망닐]
-> 삯일[상닐], 맨입[맨닙], 꽃잎[꼰닙]
-> 내복약[내봉냑], 색연필[생년필], 직행열차[지캥녈차]
-> 늑막염[능망념], 콩엿[콩녇], 담요[담뇨]
-> 눈요기[눈뇨기], 영업용[영엄뇽], 식용유[시굥뉴]
-> 국민윤리[궁민뉼리], 밤윳[밤뉻]
다만, 다음과 같은 말들은 'ㄴ'소리를 첨가하여 발음하되, 표기대로 발음할 수 있다.
-> 이죽이죽[이중니죽/이주기죽], 야금야금[야금냐금/야그먀금]
-> 검열[검녈/거멸], 욜랑욜랑[욜랑뇰랑/욜랑욜랑]
-> 금융[금늉/그뮹]
[붙임 1] 'ㄹ' 받침 뒤에 첨가되는 'ㄴ'소리는 [ㄹ]로 발음한다.
-> 들일[들릴], 솔잎[솔립], 설익다[설릭따]
-> 물약[물략], 불여우[불려우], 서울역[서울력]
-> 물엿[물렫], 휘발유[휘발류], 유들유들[유들류들]
[붙임 2] 두 단어를 이어서 한 마디로 발음하는 경우에도 이에 준한다.
-> 한 일[한 닐], 옷 입다[온 닙따], 서른여섯[서른녀섣]
-> 3연대[삼년대], 먹은 엿[머근 녇]
-> 할 일[할릴], 잘 입다[잘 립따], 스물여섯[스물려섣]
-> 1연대[일련대], 먹을 엿[머글 렫]
다만, 다음과 같은 단어에서는 'ㄴ(ㄹ)'소리를 첨가하여 발음하지 않는다.
-> 6·25[유기오], 3·1절[사밀쩔], 송별연[송벼련], 등용문[등용문]

30
제30항 사이시옷이 붙는 단어는 다음과 같이 발음한다.
1. 'ㄱ, ㄷ, ㅂ, ㅅ, ㅈ'으로 시작되는 단어 앞에 사이시옷이 올 때에는 이들 자음만을 된소리로 발음하는 것을 원칙으로 하되, 사이시옷을 [ㄷ]으로 발음하는 것도 허용한다.
-> 냇가[내까/낻까], 샛길[새낄/샏낄], 빨랫돌[빨래똘/빨랟똘]
-> 콧등[코뜽/콛뜽], 깃발[기빨/긷빨], 대팻밥[대패빱/대팯빱]
-> 햇살[해쌀/핻쌀], 뱃속[배쏙/밷쏙], 뱃전[배쩐/밷쩐]
-> 고갯짓[고개찓/고갣찓]
2. 사이시옷 뒤에 'ㄴ, ㅁ'이 결합되는 경우에는 [ㄴ]으로 발음한다.
-> 콧날[콘날], 아랫니[아랜니]
-> 툇마루[퇸마루], 뱃머리[밴머리]
3. 사이시옷 뒤에 '이'소리가 결합되는 경우에는 [ㄴㄴ]으로 발음한다.
-> 베갯잇[베갣닏→베갠닏], 깻잎[깬닙]
-> 나뭇잎[나문닙], 도리깻열[도리깬녈]
-> 뒷윷[뒨뉻]

\end{minted}

\subsection{Modified G2PK Rule} \label{sec:modified_g2pk_rule}
G2PK의 규칙을 바탕으로, 본 프로젝트에서 사용한 규칙은 Figure \ref{fig:modified_g2pk_rule}과 같다.
\begin{figure*}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/modified_rules.png}
    \caption{Modified G2PK Rule}
    \label{fig:modified_g2pk_rule}
\end{figure*}


\bigskip
\bibliography{aaai25}

\end{document}
